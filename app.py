"""
Streamlit UI for Hybrid AI Agent System

ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆFoundry Localï¼‰ã¨ã‚¯ãƒ©ã‚¦ãƒ‰LLMï¼ˆAzure AIï¼‰ã‚’çµ„ã¿åˆã‚ã›ãŸ
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®UIã‚’æä¾›ã™ã‚‹ã€‚

MCPã‚µãƒ¼ãƒãƒ¼åˆ¶å¾¡ãƒ‘ãƒãƒ«ã¨ãƒ­ã‚°è¡¨ç¤ºæ©Ÿèƒ½ã‚’å«ã‚€ã€‚

å®Ÿè¡Œæ–¹æ³•:
    streamlit run app.py
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path

import streamlit as st
from azure.identity.aio import AzureCliCredential

from agent_framework import ChatAgent, MCPStreamableHTTPTool, FunctionResultContent, TextContent
from agent_framework.azure import AzureAIAgentClient

from common.llm_logger import LLMLogEntry, llm_logger
from common.prompt_loader import get_prompts_for_agent
from medical.agent import SYMPTOM_CHECKER_INSTRUCTIONS

# MCPã‚µãƒ¼ãƒãƒ¼é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆåŒ»ç™‚ï¼‰
from mcp_server.mcp_state import mcp_state, ServerStatus, TunnelStatus
from mcp_server.mcp_medical_server import (
    get_mcp_server,
    run_mcp_server,
    stop_mcp_server,
    MCP_SERVER_PORT,
)


def append_runtime_data(message: str) -> str:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãã®ã¾ã¾è¿”ã™ã€‚

    æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¤œæŸ»çµæœãªã©ï¼‰ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ„ãƒ¼ãƒ«å†…ã§
    ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ãŸã‚ã€ã“ã“ã§ã¯è¿½è¨˜ã—ãªã„ã€‚
    ã“ã‚Œã«ã‚ˆã‚Šã€Azure AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¯å€‹äººæƒ…å ±ãŒé€ä¿¡ã•ã‚Œãªã„ã€‚

    Args:
        message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

    Returns:
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆæ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰
    """
    # æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ„ãƒ¼ãƒ«å†…ã§ç›´æ¥èª­ã¿è¾¼ã‚€ãŸã‚ã€
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ãã®ã¾ã¾è¿”ã™
    return message


def create_log_callback(placeholder):
    """Streamlitãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«æ›¸ãè¾¼ã‚€ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½œæˆ"""
    log_display = []

    def callback(entry: LLMLogEntry):
        # å…¥åŠ›ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆresponse_textãŒã¾ã ãªã„å ´åˆï¼‰
        if entry.response_text is None:
            log_display.append(f"### {entry.tool_name}")
            log_display.append("**System Prompt:**")
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé•·ã„å ´åˆã¯åˆ‡ã‚Šè©°ã‚
            prompt_preview = entry.system_prompt[:500]
            if len(entry.system_prompt) > 500:
                prompt_preview += "..."
            log_display.append(f"```\n{prompt_preview}\n```")
            log_display.append("**User Content (Input):**")
            # å…¥åŠ›ãŒé•·ã„å ´åˆã¯åˆ‡ã‚Šè©°ã‚
            input_preview = entry.user_content[:800]
            if len(entry.user_content) > 800:
                input_preview += "..."
            log_display.append(f"```\n{input_preview}\n```")
        else:
            # å‡ºåŠ›ãƒ•ã‚§ãƒ¼ã‚º
            log_display.append("**Output:**")
            if entry.parsed_result:
                output_json = json.dumps(
                    entry.parsed_result, indent=2, ensure_ascii=False
                )
                # å‡ºåŠ›ãŒé•·ã„å ´åˆã¯åˆ‡ã‚Šè©°ã‚
                if len(output_json) > 1500:
                    output_json = output_json[:1500] + "\n..."
                log_display.append(f"```json\n{output_json}\n```")
            else:
                log_display.append(f"```\n{entry.response_text[:1000]}\n```")
            log_display.append("---")

        placeholder.markdown("\n".join(log_display))

    return callback


async def run_agent_stream(agent_type: str, user_message: str, placeholders: dict):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ"""

    print(f"\n{'='*60}")
    print(f"[Streamlit] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œé–‹å§‹: {agent_type}")
    print(f"[Streamlit] ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_message[:100]}{'...' if len(user_message) > 100 else ''}")

    # å®Ÿè¡Œæ™‚ã«æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã‚’è¿½è¨˜ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯è¦‹ã›ãªã„ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚è¾¼ã‚€ï¼‰
    expanded_message = append_runtime_data(user_message)

    # ãƒ­ã‚¬ãƒ¼ã«ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¨­å®š
    llm_logger.clear()
    llm_logger.set_callback(create_log_callback(placeholders["local_llm"]))

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šï¼ˆåŒ»ç™‚è¨ºæ–­ï¼‰
    instructions = SYMPTOM_CHECKER_INSTRUCTIONS
    # MCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ï¼ˆDev TunnelçµŒç”±ã§ãƒ­ãƒ¼ã‚«ãƒ«MCPã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šï¼‰
    # ã“ã‚Œã«ã‚ˆã‚Šã€å€‹äººæƒ…å ±ï¼ˆæ‚£è€…ãƒ‡ãƒ¼ã‚¿ï¼‰ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§å‡¦ç†ã•ã‚Œã€
    # ã‚¯ãƒ©ã‚¦ãƒ‰ã«ã¯åŒ¿ååŒ–ã•ã‚ŒãŸã‚µãƒãƒªãƒ¼ã®ã¿ãŒé€ä¿¡ã•ã‚Œã‚‹
    mcp_url = mcp_state.tunnel_url
    if not mcp_url:
        placeholders["azure_llm"].error(
            "âš ï¸ åŒ»ç™‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯Dev Tunnel URLã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚\n\n"
            "1. MCPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•\n"
            "2. Dev Tunnelã‚’èµ·å‹•: `devtunnel host --port-numbers 8081`\n"
            "3. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«Dev Tunnel URLã‚’å…¥åŠ›"
        )
        print(f"[Streamlit] ã‚¨ãƒ©ãƒ¼: Dev Tunnel URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print(f"{'='*60}\n")
        return None
    print(f"[Streamlit] MCPãƒ„ãƒ¼ãƒ«ä½¿ç”¨: URL={mcp_url}")
    tools = MCPStreamableHTTPTool(
        name="LocalMedicalContext",
        url=mcp_url,
        timeout=600,           # HTTP POST: 600ç§’ï¼ˆ10åˆ†ï¼‰
        sse_read_timeout=600   # SSEèª­å–: 600ç§’ï¼ˆ10åˆ†ï¼‰
    )
    name = "hybrid-symptom-checker"

    # --- ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…ˆã«è¡¨ç¤º ---
    input_display = []
    input_display.append("### System Prompt (Instructions)")
    prompt_preview = instructions[:500]
    if len(instructions) > 500:
        prompt_preview += "..."
    input_display.append(f"```\n{prompt_preview}\n```")

    input_display.append("### User Message")
    user_preview = expanded_message[:800]
    if len(expanded_message) > 800:
        user_preview += "..."
    input_display.append(f"```\n{user_preview}\n```")

    input_display.append("---")
    input_display.append("### Response")

    base_display = "\n".join(input_display)
    placeholders["azure_llm"].markdown(base_display)

    print(f"[Streamlit] Azure AI Foundry Agent ä½œæˆä¸­... (name={name})")

    async with (
        AzureCliCredential() as credential,
        ChatAgent(
            chat_client=AzureAIAgentClient(async_credential=credential),
            instructions=instructions,
            tools=tools,
            name=name,
        ) as agent,
    ):
        print(f"[Streamlit] Azure AI ã¸ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡...")
        full_text = ""
        tool_calls_displayed = []
        tool_results_displayed = []  # ãƒ„ãƒ¼ãƒ«çµæœè¡¨ç¤ºæ¸ˆã¿ã®call_idã‚’è¿½è·¡

        async for update in agent.run_stream(expanded_message):
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
            if update.text:
                full_text += update.text
                placeholders["azure_llm"].markdown(base_display + "\n" + full_text + "â–Œ")

            # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’æ¤œå‡ºã—ã¦è¡¨ç¤º
            for content in update.contents or []:
                if hasattr(content, "name") and hasattr(content, "call_id"):
                    # FunctionCallContent
                    call_id = getattr(content, "call_id", "")
                    if call_id not in tool_calls_displayed:
                        tool_calls_displayed.append(call_id)
                        print(f"[Streamlit] ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æ¤œå‡º: {content.name}")
                        try:
                            args = content.parse_arguments()
                            args_json = json.dumps(args, indent=2, ensure_ascii=False)
                            print(f"[Streamlit] ãƒ„ãƒ¼ãƒ«å¼•æ•°: {args_json[:200]}{'...' if len(args_json) > 200 else ''}")
                        except Exception:
                            args_json = str(getattr(content, "arguments", ""))

                        placeholders["tool_calls"].info(
                            f"**Tool:** {content.name}\n\n"
                            f"**Arguments:**\n```json\n{args_json[:500]}\n```"
                        )

                # FunctionResultContentï¼ˆãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœï¼‰ã‚’æ¤œå‡ºã—ã¦è¡¨ç¤º
                elif isinstance(content, FunctionResultContent):
                    call_id = getattr(content, "call_id", "")
                    if call_id not in tool_results_displayed:
                        tool_results_displayed.append(call_id)

                        result_data = content.result
                        exception_data = content.exception

                        print(f"[Streamlit] ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœå—ä¿¡: call_id={call_id}")

                        # çµæœã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                        if exception_data:
                            result_display = f"Error: {str(exception_data)}"
                        else:
                            if isinstance(result_data, str):
                                try:
                                    parsed = json.loads(result_data)
                                    result_display = json.dumps(parsed, indent=2, ensure_ascii=False)
                                except json.JSONDecodeError:
                                    result_display = result_data
                            elif isinstance(result_data, dict):
                                result_display = json.dumps(result_data, indent=2, ensure_ascii=False)
                            elif isinstance(result_data, list):
                                # TextContentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã‚’å‡¦ç†
                                texts = []
                                for item in result_data:
                                    if hasattr(item, 'text'):
                                        texts.append(item.text)
                                    else:
                                        texts.append(str(item))
                                combined_text = "\n".join(texts)
                                try:
                                    parsed = json.loads(combined_text)
                                    result_display = json.dumps(parsed, indent=2, ensure_ascii=False)
                                except json.JSONDecodeError:
                                    result_display = combined_text
                            else:
                                result_display = str(result_data) if result_data else "(empty)"

                        print(f"[Streamlit] ãƒ„ãƒ¼ãƒ«çµæœ: {result_display[:200]}{'...' if len(result_display) > 200 else ''}")

                        # UIè¡¨ç¤º
                        with placeholders["tool_calls"]:
                            st.markdown("---")
                            st.markdown("**MCPãƒ„ãƒ¼ãƒ«å¿œç­”:**")
                            if len(result_display) > 500:
                                with st.expander("è©³ç´°ã‚’è¡¨ç¤º", expanded=False):
                                    st.code(result_display, language="json")
                            else:
                                st.code(result_display[:1000], language="json")

        # æœ€çµ‚çµæœï¼ˆã‚«ãƒ¼ã‚½ãƒ«ãªã—ï¼‰
        placeholders["azure_llm"].markdown(base_display + "\n" + full_text)
        print(f"[Streamlit] å‡¦ç†å®Œäº†")
        print(f"{'='*60}\n")
        return full_text


def render_mcp_server_panel():
    """MCPã‚µãƒ¼ãƒãƒ¼åˆ¶å¾¡ãƒ‘ãƒãƒ«ã‚’è¡¨ç¤º"""
    st.subheader("ğŸŒ MCPã‚µãƒ¼ãƒãƒ¼ (åŒ»ç™‚è¨ºæ–­)")

    # ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ã®è¡¨ç¤º
    status = mcp_state.status
    if status == ServerStatus.RUNNING:
        st.success(f"âœ… å®Ÿè¡Œä¸­ - ãƒãƒ¼ãƒˆ {mcp_state.port}")
    elif status == ServerStatus.STARTING:
        st.warning("â³ èµ·å‹•ä¸­...")
    elif status == ServerStatus.ERROR:
        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {mcp_state.error_message}")
    else:
        st.info("â¹ï¸ åœæ­¢ä¸­")

    # èµ·å‹•/åœæ­¢ãƒœã‚¿ãƒ³
    col1, col2 = st.columns(2)
    with col1:
        if st.button(
            "â–¶ï¸ èµ·å‹•",
            disabled=(status == ServerStatus.RUNNING),
            use_container_width=True,
        ):
            run_mcp_server()
            st.rerun()

    with col2:
        if st.button(
            "â¹ï¸ åœæ­¢",
            disabled=(status != ServerStatus.RUNNING),
            use_container_width=True,
        ):
            stop_mcp_server()
            st.rerun()

    # URLè¡¨ç¤º
    if status == ServerStatus.RUNNING:
        st.markdown("**ãƒ­ãƒ¼ã‚«ãƒ«URL:**")
        st.code(mcp_state.local_url, language=None)

        # Dev TunnelçŠ¶æ…‹è¡¨ç¤º
        st.markdown("**Dev Tunnel:**")
        tunnel_status = mcp_state.tunnel_status

        if tunnel_status == TunnelStatus.RUNNING:
            st.success("âœ… æ¥ç¶šæ¸ˆã¿")
        elif tunnel_status == TunnelStatus.STARTING:
            st.warning("â³ æ¥ç¶šä¸­...")
        elif tunnel_status == TunnelStatus.NOT_INSTALLED:
            st.error("âŒ devtunnel CLIãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            st.caption("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: `winget install Microsoft.devtunnel`")
        elif tunnel_status == TunnelStatus.NOT_LOGGED_IN:
            st.error("âŒ devtunnelã¸ã®ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™")
            st.caption("ãƒ­ã‚°ã‚¤ãƒ³: `devtunnel user login`")
        elif tunnel_status == TunnelStatus.ERROR:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {mcp_state.tunnel_error}")
        else:
            st.info("â¹ï¸ æœªèµ·å‹•")

        # Dev Tunnel URLè¡¨ç¤º
        st.markdown("**Dev Tunnel URL:**")

        # è‡ªå‹•å–å¾—ã•ã‚ŒãŸURLãŒã‚ã‚Œã°è¡¨ç¤º
        if mcp_state.tunnel_url and mcp_state.tunnel_auto_started:
            st.code(mcp_state.tunnel_url, language=None)
            st.caption("âœ… è‡ªå‹•å–å¾—ã•ã‚Œã¾ã—ãŸ")
        else:
            # æ‰‹å‹•å…¥åŠ›æ¬„
            tunnel_url = st.text_input(
                "Dev Tunnel URLã‚’å…¥åŠ›ï¼ˆæ‰‹å‹•ï¼‰",
                value=mcp_state.tunnel_url,
                placeholder="https://<tunnel-id>.devtunnels.ms",
                label_visibility="collapsed",
            )
            if tunnel_url != mcp_state.tunnel_url:
                mcp_state.set_tunnel_url(tunnel_url)

            st.caption(
                "è‡ªå‹•å–å¾—ã«å¤±æ•—ã—ãŸå ´åˆã€æ‰‹å‹•ã§URLã‚’å…¥åŠ›ã§ãã¾ã™ã€‚\n"
                "â†’ [Dev Tunnelã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †](docs/dev-tunnel-setup.md)"
            )


def render_mcp_logs():
    """MCPãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã‚’è¡¨ç¤º"""
    st.subheader("ğŸ“‹ MCPãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°")

    # ãƒ‡ãƒãƒƒã‚°: ç¾åœ¨ã®ãƒ­ã‚°æ•°ã‚’è¡¨ç¤º
    st.caption(f"ãƒ­ã‚°æ•°: {len(mcp_state.request_logs)} | ã‚µãƒ¼ãƒãƒ¼: {mcp_state.status.value}")

    # æ›´æ–°ãƒœã‚¿ãƒ³ã¨ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ”„ æ›´æ–°", key="refresh_mcp_logs"):
            st.rerun()
    with col2:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢", key="clear_mcp_logs"):
            mcp_state.clear_logs()
            st.rerun()

    logs = mcp_state.get_recent_logs(10)

    if not logs:
        st.info("ã¾ã ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ãƒ­ã‚°ã‚’é€†é †ã§è¡¨ç¤ºï¼ˆæ–°ã—ã„ã‚‚ã®ãŒä¸Šï¼‰
    for log in reversed(logs):
        with st.expander(
            f"{log.timestamp.strftime('%H:%M:%S')} - {log.method}",
            expanded=False,
        ):
            st.markdown(f"**ãƒ¡ã‚½ãƒƒãƒ‰:** `{log.method}`")

            if log.tool_name:
                st.markdown(f"**ãƒ„ãƒ¼ãƒ«:** `{log.tool_name}`")

            if log.tool_arguments:
                st.markdown("**å¼•æ•°:**")
                st.json(log.tool_arguments)

            if log.llm_input:
                st.markdown("**Foundry Local å…¥åŠ›:**")
                if len(log.llm_input) > 500:
                    with st.expander("å…¥åŠ›å†…å®¹ã‚’è¡¨ç¤º", expanded=False):
                        st.code(log.llm_input, language=None)
                else:
                    st.code(log.llm_input, language=None)

            if log.llm_output:
                st.markdown("**Foundry Local å‡ºåŠ›:**")
                if len(log.llm_output) > 800:
                    with st.expander("å‡ºåŠ›å†…å®¹ã‚’è¡¨ç¤º", expanded=False):
                        st.code(log.llm_output, language=None)
                else:
                    st.code(log.llm_output, language=None)

            if log.response:
                st.markdown("**ãƒ¬ã‚¹ãƒãƒ³ã‚¹:**")
                try:
                    st.json(log.response)
                except Exception:
                    st.code(str(log.response)[:500], language=None)

            if log.error:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {log.error}")

            if log.duration_ms:
                st.caption(f"å‡¦ç†æ™‚é–“: {log.duration_ms:.1f}ms")


def main():
    st.set_page_config(page_title="Hybrid AI Agent", page_icon="ğŸ¤–", layout="wide")
    st.title("ğŸ¤– Hybrid AI Agent System")
    st.caption("Local LLM (Foundry Local) + Cloud LLM (Azure AI) + MCP Server")

    # åŒ»ç™‚è¨ºæ–­ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã¿
    agent_type = "medical"

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
    if "user_input" not in st.session_state:
        st.session_state.user_input = ""

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("è¨­å®š")

        # MCPã‚µãƒ¼ãƒãƒ¼åˆ¶å¾¡ãƒ‘ãƒãƒ«ï¼ˆåŒ»ç™‚ï¼‰
        render_mcp_server_panel()

        st.divider()
        st.markdown(
            """
        ### ä½¿ã„æ–¹
        1. MCPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ï¼ˆãƒãƒ¼ãƒˆ8081ï¼‰
        2. Dev Tunnelã‚’èµ·å‹•ã—ã¦URLã‚’å…¥åŠ›
        3. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠã—ã¦èª­ã¿è¾¼ã‚€
        4. ã€Œå®Ÿè¡Œã€ã‚’ã‚¯ãƒªãƒƒã‚¯

        ### è¡¨ç¤ºå†…å®¹
        - **MCPã‚µãƒ¼ãƒãƒ¼**: ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ã¨ãƒ­ã‚°
        - **ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—**: Azure LLMãŒã©ã®ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—ãŸã‹
        - **Local LLM**: Foundry Localã¸ã®å…¥å‡ºåŠ›
        - **Azure LLM**: ã‚¯ãƒ©ã‚¦ãƒ‰ã‹ã‚‰ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”
        """
        )

    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢: ã‚¿ãƒ–ã§åˆ‡ã‚Šæ›¿ãˆ
    tab1, tab2 = st.tabs(["ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ", "ğŸ“‹ MCPãƒ­ã‚°"])

    with tab1:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠ
        prompt_files = get_prompts_for_agent(agent_type)

        if prompt_files:
            col_select, col_load = st.columns([3, 1])
            with col_select:
                selected_prompt = st.selectbox(
                    "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠ",
                    options=prompt_files,
                    format_func=lambda p: f"{p.title} - {p.description}" if p.description else p.title,
                    key="prompt_select",
                )
            with col_load:
                st.write("")  # ä½ç½®èª¿æ•´ç”¨
                if st.button("ğŸ“„ èª­ã¿è¾¼ã‚€", use_container_width=True):
                    if selected_prompt:
                        st.session_state.message_input = selected_prompt.content
                        st.rerun()
        else:
            st.info(f"{agent_type}/prompts/ ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«(.md)ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›
        user_message = st.text_area(
            "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›",
            value=st.session_state.user_input,
            height=200,
            key="message_input",
        )

        run_button = st.button("ğŸš€ å®Ÿè¡Œ", type="primary", use_container_width=True)

        if run_button and user_message.strip():
            # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("ğŸ”§ ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã— & MCPå¿œç­”")
                tool_placeholder = st.container()

                # st.subheader("ğŸ’» Local LLM (Foundry Local)")
                local_placeholder = st.empty()

            with col2:
                st.subheader("â˜ï¸ Azure LLM ãƒ¬ã‚¹ãƒãƒ³ã‚¹")
                azure_placeholder = st.empty()

            placeholders = {
                "tool_calls": tool_placeholder,
                "local_llm": local_placeholder,
                "azure_llm": azure_placeholder,
            }

            with st.spinner("å‡¦ç†ä¸­..."):
                try:
                    result = asyncio.run(
                        run_agent_stream(agent_type, user_message, placeholders)
                    )
                    st.success("âœ… å®Œäº†!")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        elif run_button:
            st.warning("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    with tab2:
        # MCPãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°è¡¨ç¤º
        render_mcp_logs()


if __name__ == "__main__":
    main()
