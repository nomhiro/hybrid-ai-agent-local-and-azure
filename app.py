"""
Streamlit UI for Hybrid AI Agent System

ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆFoundry Localï¼‰ã¨ã‚¯ãƒ©ã‚¦ãƒ‰LLMï¼ˆAzure AIï¼‰ã‚’çµ„ã¿åˆã‚ã›ãŸ
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®UIã‚’æä¾›ã™ã‚‹ã€‚

å®Ÿè¡Œæ–¹æ³•:
    streamlit run app.py
"""

import asyncio
import json
from pathlib import Path

import streamlit as st
from azure.identity.aio import AzureCliCredential

from agent_framework import ChatAgent
from agent_framework.azure import AzureAIAgentClient

from common.llm_logger import LLMLogEntry, llm_logger
from common.prompt_loader import get_prompts_for_agent
from finance.agent import (
    FINANCIAL_PLANNER_INSTRUCTIONS,
    analyze_financial_assets,
    analyze_life_plan,
)
from medical.agent import (
    SYMPTOM_CHECKER_INSTRUCTIONS,
    summarize_lab_report,
)


def append_runtime_data(message: str, agent_type: str) -> str:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãã®ã¾ã¾è¿”ã™ã€‚

    æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ï¼ˆé‡‘èè³‡ç”£ã€æ¤œæŸ»çµæœãªã©ï¼‰ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ„ãƒ¼ãƒ«å†…ã§
    ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ãŸã‚ã€ã“ã“ã§ã¯è¿½è¨˜ã—ãªã„ã€‚
    ã“ã‚Œã«ã‚ˆã‚Šã€Azure AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¯å€‹äººæƒ…å ±ãŒé€ä¿¡ã•ã‚Œãªã„ã€‚

    Args:
        message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        agent_type: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ï¼ˆ"finance" ã¾ãŸã¯ "medical"ï¼‰

    Returns:
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆæ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰
    """
    # æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ„ãƒ¼ãƒ«å†…ã§ç›´æ¥èª­ã¿è¾¼ã‚€ãŸã‚ã€
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ãã®ã¾ã¾è¿”ã™
    return message


def create_log_callback(placeholder):
    """Streamlitãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«æ›¸ãè¾¼ã‚€ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½œæˆ"""
    log_display = []

    def callback(entry: LLMLogEntry):
        # å…¥åŠ›ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆresponse_textãŒã¾ã ãªã„å ´åˆï¼‰
        if entry.response_text is None:
            log_display.append(f"### {entry.tool_name}")
            log_display.append("**System Prompt:**")
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé•·ã„å ´åˆã¯åˆ‡ã‚Šè©°ã‚
            prompt_preview = entry.system_prompt[:500]
            if len(entry.system_prompt) > 500:
                prompt_preview += "..."
            log_display.append(f"```\n{prompt_preview}\n```")
            log_display.append("**User Content (Input):**")
            # å…¥åŠ›ãŒé•·ã„å ´åˆã¯åˆ‡ã‚Šè©°ã‚
            input_preview = entry.user_content[:800]
            if len(entry.user_content) > 800:
                input_preview += "..."
            log_display.append(f"```\n{input_preview}\n```")
        else:
            # å‡ºåŠ›ãƒ•ã‚§ãƒ¼ã‚º
            log_display.append("**Output:**")
            if entry.parsed_result:
                output_json = json.dumps(
                    entry.parsed_result, indent=2, ensure_ascii=False
                )
                # å‡ºåŠ›ãŒé•·ã„å ´åˆã¯åˆ‡ã‚Šè©°ã‚
                if len(output_json) > 1500:
                    output_json = output_json[:1500] + "\n..."
                log_display.append(f"```json\n{output_json}\n```")
            else:
                log_display.append(f"```\n{entry.response_text[:1000]}\n```")
            log_display.append("---")

        placeholder.markdown("\n".join(log_display))

    return callback


async def run_agent_stream(agent_type: str, user_message: str, placeholders: dict):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ"""

    # å®Ÿè¡Œæ™‚ã«æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã‚’è¿½è¨˜ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯è¦‹ã›ãªã„ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚è¾¼ã‚€ï¼‰
    expanded_message = append_runtime_data(user_message, agent_type)

    # ãƒ­ã‚¬ãƒ¼ã«ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¨­å®š
    llm_logger.clear()
    llm_logger.set_callback(create_log_callback(placeholders["local_llm"]))

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’é¸æŠ
    if agent_type == "finance":
        instructions = FINANCIAL_PLANNER_INSTRUCTIONS
        tools = [analyze_financial_assets, analyze_life_plan]
        name = "hybrid-financial-planner"
    else:
        instructions = SYMPTOM_CHECKER_INSTRUCTIONS
        tools = [summarize_lab_report]
        name = "hybrid-symptom-checker"

    # --- ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…ˆã«è¡¨ç¤º ---
    input_display = []
    input_display.append("### System Prompt (Instructions)")
    prompt_preview = instructions[:500]
    if len(instructions) > 500:
        prompt_preview += "..."
    input_display.append(f"```\n{prompt_preview}\n```")

    input_display.append("### User Message")
    user_preview = expanded_message[:800]
    if len(expanded_message) > 800:
        user_preview += "..."
    input_display.append(f"```\n{user_preview}\n```")

    input_display.append("---")
    input_display.append("### Response")

    base_display = "\n".join(input_display)
    placeholders["azure_llm"].markdown(base_display)

    async with (
        AzureCliCredential() as credential,
        ChatAgent(
            chat_client=AzureAIAgentClient(async_credential=credential),
            instructions=instructions,
            tools=tools,
            name=name,
        ) as agent,
    ):
        full_text = ""
        tool_calls_displayed = []

        async for update in agent.run_stream(expanded_message):
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
            if update.text:
                full_text += update.text
                placeholders["azure_llm"].markdown(base_display + "\n" + full_text + "â–Œ")

            # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’æ¤œå‡ºã—ã¦è¡¨ç¤º
            for content in update.contents or []:
                if hasattr(content, "name") and hasattr(content, "call_id"):
                    # FunctionCallContent
                    call_id = getattr(content, "call_id", "")
                    if call_id not in tool_calls_displayed:
                        tool_calls_displayed.append(call_id)
                        try:
                            args = content.parse_arguments()
                            args_json = json.dumps(args, indent=2, ensure_ascii=False)
                        except Exception:
                            args_json = str(getattr(content, "arguments", ""))

                        placeholders["tool_calls"].info(
                            f"**Tool:** {content.name}\n\n"
                            f"**Arguments:**\n```json\n{args_json[:500]}\n```"
                        )

        # æœ€çµ‚çµæœï¼ˆã‚«ãƒ¼ã‚½ãƒ«ãªã—ï¼‰
        placeholders["azure_llm"].markdown(base_display + "\n" + full_text)
        return full_text


def main():
    st.set_page_config(page_title="Hybrid AI Agent", page_icon="ğŸ¤–", layout="wide")
    st.title("ğŸ¤– Hybrid AI Agent System")
    st.caption("Local LLM (Foundry Local) + Cloud LLM (Azure AI)")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
    if "user_input" not in st.session_state:
        st.session_state.user_input = ""

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("è¨­å®š")
        agent_type = st.selectbox(
            "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸æŠ",
            options=["finance", "medical"],
            format_func=lambda x: (
                "ğŸ’° ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚·ãƒ£ãƒ«ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼" if x == "finance" else "ğŸ¥ åŒ»ç™‚ãƒˆãƒªã‚¢ãƒ¼ã‚¸"
            ),
        )

        st.divider()
        st.markdown(
            """
        ### ä½¿ã„æ–¹
        1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸æŠ
        2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠã—ã¦èª­ã¿è¾¼ã‚€ã€ã¾ãŸã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›
        3. ã€Œå®Ÿè¡Œã€ã‚’ã‚¯ãƒªãƒƒã‚¯

        ### è¡¨ç¤ºå†…å®¹
        - **ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—**: Azure LLMãŒã©ã®ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—ãŸã‹
        - **Local LLM**: Foundry Localã¸ã®å…¥å‡ºåŠ›
        - **Azure LLM**: ã‚¯ãƒ©ã‚¦ãƒ‰ã‹ã‚‰ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”
        """
        )

    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠ
    prompt_files = get_prompts_for_agent(agent_type)

    if prompt_files:
        col_select, col_load = st.columns([3, 1])
        with col_select:
            selected_prompt = st.selectbox(
                "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠ",
                options=prompt_files,
                format_func=lambda p: f"{p.title} - {p.description}" if p.description else p.title,
                key="prompt_select",
            )
        with col_load:
            st.write("")  # ä½ç½®èª¿æ•´ç”¨
            if st.button("ğŸ“„ èª­ã¿è¾¼ã‚€", use_container_width=True):
                if selected_prompt:
                    st.session_state.message_input = selected_prompt.content
                    st.rerun()
    else:
        st.info(f"{agent_type}/prompts/ ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«(.md)ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›
    user_message = st.text_area(
        "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›",
        value=st.session_state.user_input,
        height=200,
        key="message_input",
    )

    run_button = st.button("ğŸš€ å®Ÿè¡Œ", type="primary", use_container_width=True)

    if run_button and user_message.strip():
        # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ”§ ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—")
            tool_placeholder = st.container()

            st.subheader("ğŸ’» Local LLM (Foundry Local)")
            local_placeholder = st.empty()

        with col2:
            st.subheader("â˜ï¸ Azure LLM ãƒ¬ã‚¹ãƒãƒ³ã‚¹")
            azure_placeholder = st.empty()

        placeholders = {
            "tool_calls": tool_placeholder,
            "local_llm": local_placeholder,
            "azure_llm": azure_placeholder,
        }

        with st.spinner("å‡¦ç†ä¸­..."):
            try:
                result = asyncio.run(
                    run_agent_stream(agent_type, user_message, placeholders)
                )
                st.success("âœ… å®Œäº†!")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    elif run_button:
        st.warning("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()
